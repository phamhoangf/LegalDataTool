#!/usr/bin/env python3
"""
BM25-based similarity checker for legal questions
"""

import re
import json
from typing import List, Dict, Any, Tuple
from rank_bm25 import BM25Okapi
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

class QuestionSimilarityChecker:
    """
    Ki·ªÉm tra t∆∞∆°ng ƒë·ªìng c√¢u h·ªèi s·ª≠ d·ª•ng BM25 v√† TF-IDF
    """
    
    def __init__(self, similarity_threshold: float = 0.8):
        """
        Args:
            similarity_threshold: Ng∆∞·ª°ng t∆∞∆°ng ƒë·ªìng (0-1), > threshold = t∆∞∆°ng ƒë·ªìng
        """
        self.similarity_threshold = similarity_threshold
        self.bm25 = None
        self.tfidf_vectorizer = None
        self.tfidf_matrix = None
        self.existing_questions = []
        self.preprocessed_questions = []
        
    def preprocess_text(self, text: str) -> List[str]:
        """
        Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n ti·∫øng Vi·ªát
        """
        if not text:
            return []
            
        # Chuy·ªÉn th∆∞·ªùng
        text = text.lower()
        
        # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát, gi·ªØ l·∫°i ch·ªØ c√°i, s·ªë v√† kho·∫£ng tr·∫Øng
        text = re.sub(r'[^\w\s]', ' ', text)
        
        # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
        text = re.sub(r'\s+', ' ', text).strip()
        
        # T√°ch t·ª´ ƒë∆°n gi·∫£n (split by space)
        words = text.split()
        
        # Lo·∫°i b·ªè t·ª´ d·ª´ng ƒë∆°n gi·∫£n
        stop_words = {
            'l√†', 'c·ªßa', 'v√†', 'c√≥', 'trong', 'v·ªõi', 'theo', 'ƒë·ªÉ', 'ƒë∆∞·ª£c', 'c√°c', 
            'm·ªôt', 'n√†y', 'ƒë√≥', 'nh·ªØng', 't·ª´', 'tr√™n', 'd∆∞·ªõi', 'v·ªÅ', 'cho', 'hay',
            'b·∫±ng', 'nh∆∞', 'khi', 'n√†o', 'g√¨', 'ai', 'ƒë√¢u', 'sao', 'bao', 'nhi·ªÅu'
        }
        
        words = [word for word in words if word not in stop_words and len(word) > 1]
        
        return words
    
    def update_corpus(self, questions_data: List[Dict[str, Any]]):
        """
        C·∫≠p nh·∫≠t corpus v·ªõi c√°c c√¢u h·ªèi hi·ªán c√≥ trong database
        
        Args:
            questions_data: List c√°c dict ch·ª©a c√¢u h·ªèi v√† metadata
        """
        self.existing_questions = []
        self.preprocessed_questions = []
        
        for item in questions_data:
            # L·∫•y c√¢u h·ªèi t·ª´ content
            if isinstance(item.get('content'), str):
                content = json.loads(item['content'])
            else:
                content = item.get('content', {})
            
            question = content.get('question', '')
            if question:
                self.existing_questions.append({
                    'id': item.get('id'),
                    'question': question,
                    'data_type': item.get('data_type'),
                    'content': content
                })
                
                # Ti·ªÅn x·ª≠ l√Ω c√¢u h·ªèi
                preprocessed = self.preprocess_text(question)
                self.preprocessed_questions.append(preprocessed)
        
        if self.preprocessed_questions:
            # Kh·ªüi t·∫°o BM25
            self.bm25 = BM25Okapi(self.preprocessed_questions)
            
            # Kh·ªüi t·∫°o TF-IDF
            question_texts = [' '.join(words) for words in self.preprocessed_questions]
            self.tfidf_vectorizer = TfidfVectorizer()
            self.tfidf_matrix = self.tfidf_vectorizer.fit_transform(question_texts)
            
            print(f"üìö Updated similarity corpus with {len(self.existing_questions)} questions")
        else:
            print("üìö No existing questions found - similarity checking disabled")
    
    def find_similar_questions(self, new_question: str, top_k: int = 5) -> List[Tuple[Dict, float]]:
        """
        T√¨m c√°c c√¢u h·ªèi t∆∞∆°ng ƒë·ªìng v·ªõi c√¢u h·ªèi m·ªõi
        
        Args:
            new_question: C√¢u h·ªèi m·ªõi c·∫ßn ki·ªÉm tra
            top_k: S·ªë l∆∞·ª£ng c√¢u h·ªèi t∆∞∆°ng ƒë·ªìng nh·∫•t tr·∫£ v·ªÅ
            
        Returns:
            List[Tuple[Dict, float]]: (question_data, similarity_score)
        """
        if not self.bm25 or not self.existing_questions:
            return []
        
        # Ti·ªÅn x·ª≠ l√Ω c√¢u h·ªèi m·ªõi
        query_tokens = self.preprocess_text(new_question)
        if not query_tokens:
            return []
        
        # T√≠nh BM25 scores
        bm25_scores = self.bm25.get_scores(query_tokens)
        
        # Normalize BM25 scores v·ªÅ 0-1
        if len(bm25_scores) > 0:
            max_bm25 = max(bm25_scores)
            if max_bm25 > 0:
                bm25_scores = bm25_scores / max_bm25
        
        # T√≠nh TF-IDF cosine similarity (ƒë√£ ·ªü 0-1)
        query_text = ' '.join(query_tokens)
        query_tfidf = self.tfidf_vectorizer.transform([query_text])
        tfidf_scores = cosine_similarity(query_tfidf, self.tfidf_matrix).flatten()
        
        # K·∫øt h·ª£p scores (trung b√¨nh c·ªông c√≥ tr·ªçng s·ªë)
        # TF-IDF th∆∞·ªùng stable h∆°n cho similarity, n√™n cho tr·ªçng s·ªë cao h∆°n
        combined_scores = (0.3 * bm25_scores + 0.7 * tfidf_scores)
        
        # L·∫•y top_k scores cao nh·∫•t
        top_indices = np.argsort(combined_scores)[::-1][:top_k]
        
        results = []
        for idx in top_indices:
            if combined_scores[idx] > 0.1:  # Ng∆∞·ª°ng t·ªëi thi·ªÉu
                results.append((
                    self.existing_questions[idx],
                    float(combined_scores[idx])
                ))
        
        return results
    
    def is_duplicate(self, new_question: str) -> Tuple[bool, List[Tuple[Dict, float]]]:
        """
        Ki·ªÉm tra xem c√¢u h·ªèi m·ªõi c√≥ tr√πng l·∫∑p v·ªõi c√¢u h·ªèi hi·ªán c√≥ kh√¥ng
        
        Args:
            new_question: C√¢u h·ªèi m·ªõi c·∫ßn ki·ªÉm tra
            
        Returns:
            Tuple[bool, List]: (is_duplicate, similar_questions)
        """
        similar_questions = self.find_similar_questions(new_question, top_k=3)
        
        # Ki·ªÉm tra c√≥ c√¢u h·ªèi n√†o v∆∞·ª£t ng∆∞·ª°ng kh√¥ng
        is_duplicate = any(score >= self.similarity_threshold for _, score in similar_questions)
        
        return is_duplicate, similar_questions
    
    def check_batch_similarity(self, new_questions: List[str]) -> List[Dict[str, Any]]:
        """
        Ki·ªÉm tra t∆∞∆°ng ƒë·ªìng cho m·ªôt batch c√¢u h·ªèi
        
        Args:
            new_questions: List c√°c c√¢u h·ªèi m·ªõi
            
        Returns:
            List[Dict]: K·∫øt qu·∫£ ki·ªÉm tra cho t·ª´ng c√¢u h·ªèi
        """
        results = []
        
        for i, question in enumerate(new_questions):
            is_dup, similar = self.is_duplicate(question)
            
            result = {
                'index': i,
                'question': question,
                'is_duplicate': is_dup,
                'similar_questions': [
                    {
                        'question': sim_q['question'],
                        'similarity': score,
                        'data_type': sim_q['data_type'],
                        'id': sim_q['id']
                    }
                    for sim_q, score in similar
                ],
                'max_similarity': max([score for _, score in similar], default=0.0)
            }
            results.append(result)
        
        return results

def test_similarity_checker():
    """Test function cho similarity checker"""
    checker = QuestionSimilarityChecker(similarity_threshold=0.7)
    
    # Test data
    existing_questions = [
        {
            'id': 1,
            'data_type': 'word_matching',
            'content': json.dumps({
                'question': 'ƒê·ªô tu·ªïi t·ªëi thi·ªÉu ƒë·ªÉ l√°i xe m√¥ t√¥ l√† bao nhi√™u?',
                'answer': '16 tu·ªïi'
            })
        },
        {
            'id': 2,
            'data_type': 'concept_understanding', 
            'content': json.dumps({
                'question': 'Th·ªùi gian ƒë√†o t·∫°o l√Ω thuy·∫øt cho h·∫°ng A1 l√† bao nhi√™u gi·ªù?',
                'answer': '18 gi·ªù'
            })
        }
    ]
    
    checker.update_corpus(existing_questions)
    
    # Test new questions
    test_questions = [
        'Tu·ªïi t·ªëi thi·ªÉu ƒë·ªÉ ƒë∆∞·ª£c ph√©p l√°i xe m√¥ t√¥ l√† g√¨?',  # T∆∞∆°ng ƒë·ªìng cao
        'Quy ƒë·ªãnh v·ªÅ h·ªçc ph√≠ ƒë√†o t·∫°o l√°i xe l√† nh∆∞ th·∫ø n√†o?',  # Kh√°c ho√†n to√†n
        'Th·ªùi gian h·ªçc l√Ω thuy·∫øt h·∫°ng A1 bao l√¢u?'  # T∆∞∆°ng ƒë·ªìng trung b√¨nh
    ]
    
    for question in test_questions:
        is_dup, similar = checker.is_duplicate(question)
        print(f"\nüîç Question: {question}")
        print(f"   Duplicate: {is_dup}")
        for sim_q, score in similar:
            print(f"   Similar ({score:.3f}): {sim_q['question']}")

if __name__ == "__main__":
    test_similarity_checker()
