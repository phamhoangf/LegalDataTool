#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script th·ª≠ nghi·ªám parse vƒÉn b·∫£n ph√°p lu·∫≠t th√†nh c·∫•u tr√∫c JSON
Hierarchy: T√†i li·ªáu -> Ch∆∞∆°ng -> M·ª•c -> ƒêi·ªÅu
"""

import re
import json
import random
from typing import Dict, List, Any

class LegalDocumentParser:
    """Parse vƒÉn b·∫£n ph√°p lu·∫≠t th√†nh c·∫•u tr√∫c hierarchical"""
    
    def __init__(self):
        # Patterns ƒë·ªÉ nh·∫≠n di·ªán c√°c c·∫•p ƒë·ªô
        self.patterns = {
            'chuong': r'CH∆Ø∆†NG\s+([IVXLC]+|[0-9]+)\.?\s*([^\n\r]*)',
            'muc': r'M·ª•c\s+(\d+)\.?\s*([^\n\r]*)', 
            'dieu': r'ƒêi·ªÅu\s+(\d+)\.?\s*([^\n\r]*)'
        }
    
    def parse_document(self, title: str, content: str) -> Dict[str, Any]:
        """
        Parse to√†n b·ªô document th√†nh c·∫•u tr√∫c JSON
        
        Args:
            title: T√™n t√†i li·ªáu
            content: N·ªôi dung vƒÉn b·∫£n
            
        Returns:
            Dict: C·∫•u tr√∫c JSON c·ªßa t√†i li·ªáu
        """
        print(f"üìÑ Parsing document: {title}")
        
        # L√†m s·∫°ch content
        content = self._clean_content(content)
        
        lines = content.strip().split('\n')
        
        # Kh·ªüi t·∫°o structure
        document_structure = {
            'title': title,
            'type': 'document',
            'content_length': len(content),
            'chapters': [],
            'total_articles': 0,
            'metadata': {
                'has_chapters': False,
                'has_sections': False,
                'parsing_stats': {}
            }
        }
        
        # State tracking
        current_chapter = None
        current_section = None
        current_article = None
        
        article_count = 0
        
        for i, line in enumerate(lines):
            line = line.strip()
            if not line:
                continue
                
            # 1. Ki·ªÉm tra CH∆Ø∆†NG
            chapter_match = re.match(self.patterns['chuong'], line, re.IGNORECASE)
            if chapter_match:
                # T√¨m title c·ªßa ch∆∞∆°ng ·ªü d√≤ng ti·∫øp theo (n·∫øu c√≥)
                chapter_title = ""
                if i + 1 < len(lines):
                    next_line = lines[i + 1].strip()
                    # N·∫øu d√≤ng ti·∫øp theo kh√¥ng ph·∫£i l√† pattern ƒë·∫∑c bi·ªát, coi l√† title
                    if (next_line and 
                        not re.match(self.patterns['chuong'], next_line, re.IGNORECASE) and
                        not re.match(self.patterns['muc'], next_line, re.IGNORECASE) and
                        not re.match(self.patterns['dieu'], next_line, re.IGNORECASE)):
                        chapter_title = next_line
                
                current_chapter = self._create_chapter(chapter_match, i, chapter_title)
                document_structure['chapters'].append(current_chapter)
                current_section = None
                current_article = None
                document_structure['metadata']['has_chapters'] = True
                continue
            
            # 2. Ki·ªÉm tra M·ª§C
            section_match = re.match(self.patterns['muc'], line, re.IGNORECASE)
            if section_match:
                current_section = self._create_section(section_match, i)
                if current_chapter:
                    current_chapter['sections'].append(current_section)
                else:
                    # M·ª•c ƒë·ªôc l·∫≠p kh√¥ng thu·ªôc ch∆∞∆°ng n√†o
                    if 'independent_sections' not in document_structure:
                        document_structure['independent_sections'] = []
                    document_structure['independent_sections'].append(current_section)
                current_article = None
                document_structure['metadata']['has_sections'] = True
                continue
            
            # 3. Ki·ªÉm tra ƒêI·ªÄU
            article_match = re.match(self.patterns['dieu'], line, re.IGNORECASE)
            if article_match:
                current_article = self._create_article(article_match, i, lines)
                article_count += 1
                
                # G√°n article v√†o ƒë√∫ng container
                if current_section:
                    current_section['articles'].append(current_article)
                elif current_chapter:
                    current_chapter['articles'].append(current_article)
                else:
                    # Article ƒë·ªôc l·∫≠p
                    if 'independent_articles' not in document_structure:
                        document_structure['independent_articles'] = []
                    document_structure['independent_articles'].append(current_article)
                continue
        
        # Finalize document
        document_structure['total_articles'] = article_count
        document_structure['metadata']['parsing_stats'] = {
            'chapters': len(document_structure.get('chapters', [])),
            'total_sections': self._count_sections(document_structure),
            'articles': article_count
        }
        
        print(f"‚úÖ Parsed successfully:")
        print(f"   üìö Chapters: {document_structure['metadata']['parsing_stats']['chapters']}")
        print(f"   üìã Sections: {document_structure['metadata']['parsing_stats']['total_sections']}")
        print(f"   üìú Articles: {document_structure['metadata']['parsing_stats']['articles']}")
        
        return document_structure
    
    def _clean_content(self, content: str) -> str:
        """L√†m s·∫°ch content"""
        # Ch·ªâ remove extra spaces tr√™n c√πng m·ªôt d√≤ng, gi·ªØ nguy√™n newlines
        lines = content.split('\n')
        cleaned_lines = [re.sub(r'[ \t]+', ' ', line.strip()) for line in lines]
        return '\n'.join(cleaned_lines)
    
    def _create_chapter(self, match, line_num: int, chapter_title: str = "") -> Dict[str, Any]:
        """T·∫°o chapter object"""
        chapter_num = match.group(1)
        
        return {
            'type': 'chapter',
            'number': chapter_num,
            'title': chapter_title,
            'line_number': line_num,
            'sections': [],
            'articles': []
        }
    
    def _create_section(self, match, line_num: int) -> Dict[str, Any]:
        """T·∫°o section object"""
        section_num = int(match.group(1))
        section_title = match.group(2).strip()
        
        return {
            'type': 'section',
            'number': section_num,
            'title': section_title,
            'line_number': line_num,
            'articles': []
        }
    
    def _create_article(self, match, line_num: int, all_lines: List[str]) -> Dict[str, Any]:
        """T·∫°o article object v·ªõi full content"""
        article_num = int(match.group(1))
        article_title = match.group(2).strip()
        
        # L·∫•y full content c·ªßa article
        content = self._extract_article_content(line_num, all_lines)
        
        # Parse th√†nh paragraphs
        paragraphs = self._parse_paragraphs(content)
        
        return {
            'type': 'article',
            'number': article_num,
            'title': article_title,
            'line_number': line_num,
            'content': content,
            'content_length': len(content),
            'paragraphs': paragraphs
        }
    
    def _extract_article_content(self, start_line: int, all_lines: List[str]) -> str:
        """Tr√≠ch xu·∫•t full content c·ªßa m·ªôt ƒëi·ªÅu"""
        content_lines = []
        
        # B·∫Øt ƒë·∫ßu t·ª´ line hi·ªán t·∫°i
        for i in range(start_line, len(all_lines)):
            line = all_lines[i].strip()
            
            # D·ª´ng khi g·∫∑p ƒëi·ªÅu ti·∫øp theo
            if i > start_line and re.match(self.patterns['dieu'], line, re.IGNORECASE):
                break
            # D·ª´ng khi g·∫∑p ch∆∞∆°ng m·ªõi
            if i > start_line and re.match(self.patterns['chuong'], line, re.IGNORECASE):
                break
            # D·ª´ng khi g·∫∑p m·ª•c m·ªõi  
            if i > start_line and re.match(self.patterns['muc'], line, re.IGNORECASE):
                break
                
            if line:
                content_lines.append(line)
        
        return ' '.join(content_lines)
    
    def _parse_paragraphs(self, content: str) -> List[str]:
        """Parse content th√†nh paragraphs"""
        # Split theo s·ªë th·ª© t·ª± (1., 2., 3., ...)
        paragraphs = re.split(r'\s+(?=\d+\.)', content)
        return [p.strip() for p in paragraphs if p.strip()]
    
    def _count_sections(self, document: Dict[str, Any]) -> int:
        """ƒê·∫øm t·ªïng s·ªë sections"""
        total = 0
        
        # Sections in chapters
        for chapter in document.get('chapters', []):
            total += len(chapter.get('sections', []))
        
        # Independent sections
        total += len(document.get('independent_sections', []))
        
        return total
    
    def get_all_articles(self, document: Dict[str, Any]) -> List[Dict[str, Any]]:
        """L·∫•y t·∫•t c·∫£ articles t·ª´ document structure (for Monte Carlo sampling)"""
        articles = []
        document_title = document.get('title', 'Document')
        
        # Articles in chapters
        for chapter in document.get('chapters', []):
            chapter_name = f"Ch∆∞∆°ng {chapter['number']}: {chapter['title']}" if chapter['title'] else f"Ch∆∞∆°ng {chapter['number']}"
            
            # Articles tr·ª±c ti·∫øp thu·ªôc chapter
            for article in chapter.get('articles', []):
                article_info = {
                    'number': article['number'],
                    'title': article['title'],
                    'content': article['content'],
                    'content_length': article['content_length'],
                    'path': f"{document_title}, {chapter_name}"
                }
                articles.append(article_info)
            
            # Articles trong sections c·ªßa chapter
            for section in chapter.get('sections', []):
                section_name = f"M·ª•c {section['number']}: {section['title']}"
                for article in section.get('articles', []):
                    article_info = {
                        'number': article['number'],
                        'title': article['title'],
                        'content': article['content'],
                        'content_length': article['content_length'],
                        'path': f"{document_title}, {chapter_name}, {section_name}"
                    }
                    articles.append(article_info)
        
        # Independent sections
        for section in document.get('independent_sections', []):
            section_name = f"M·ª•c {section['number']}: {section['title']}"
            for article in section.get('articles', []):
                article_info = {
                    'number': article['number'],
                    'title': article['title'],
                    'content': article['content'],
                    'content_length': article['content_length'],
                    'path': f"{document_title}, {section_name}"
                }
                articles.append(article_info)
        
        # Independent articles
        for article in document.get('independent_articles', []):
            article_info = {
                'number': article['number'],
                'title': article['title'],
                'content': article['content'],
                'content_length': article['content_length'],
                'path': f"{document_title}"
            }
            articles.append(article_info)
        
        return articles
    
    def monte_carlo_sample_articles(self, articles: List[Dict[str, Any]], sample_size: int) -> List[Dict[str, Any]]:
        """
        Monte Carlo sampling for articles - completely random selection
        Ensures fair coverage over multiple generations
        
        Args:
            articles: List of all available articles
            sample_size: Number of articles to select
            
        Returns:
            List of randomly selected articles
        """
        if not articles or sample_size <= 0:
            return []
            
        if sample_size >= len(articles):
            return articles.copy()
        
        # Pure random sampling without replacement
        return random.sample(articles, sample_size)


def test_parser():
    """Test function ƒë·ªÉ validate parser"""
    
    sample_text = """
    LU·∫¨T GIAO TH√îNG ƒê∆Ø·ªúNG B·ªò
    
    CH∆Ø∆†NG I
    QUY ƒê·ªäNH CHUNG
    
    ƒêi·ªÅu 1. Ph·∫°m vi ƒëi·ªÅu ch·ªânh
    Lu·∫≠t n√†y quy ƒë·ªãnh v·ªÅ giao th√¥ng ƒë∆∞·ªùng b·ªô; quy·ªÅn, nghƒ©a v·ª• c·ªßa t·ªï ch·ª©c, c√° nh√¢n tham gia giao th√¥ng ƒë∆∞·ªùng b·ªô; quy t·∫Øc giao th√¥ng ƒë∆∞·ªùng b·ªô; t√≠n hi·ªáu giao th√¥ng ƒë∆∞·ªùng b·ªô; k·∫øt c·∫•u h·∫° t·∫ßng giao th√¥ng ƒë∆∞·ªùng b·ªô; ph∆∞∆°ng ti·ªán giao th√¥ng ƒë∆∞·ªùng b·ªô v√† ng∆∞·ªùi l√°i xe; v·∫≠n t·∫£i ƒë∆∞·ªùng b·ªô; thanh tra, x·ª≠ l√Ω vi ph·∫°m ph√°p lu·∫≠t v·ªÅ giao th√¥ng ƒë∆∞·ªùng b·ªô.
    
    ƒêi·ªÅu 2. Gi·∫£i th√≠ch t·ª´ ng·ªØ
    Trong Lu·∫≠t n√†y, c√°c t·ª´ ng·ªØ d∆∞·ªõi ƒë√¢y ƒë∆∞·ª£c hi·ªÉu nh∆∞ sau:
    1. Giao th√¥ng ƒë∆∞·ªùng b·ªô l√† ho·∫°t ƒë·ªông di chuy·ªÉn c·ªßa ng∆∞·ªùi v√† ph∆∞∆°ng ti·ªán giao th√¥ng qua ƒë∆∞·ªùng b·ªô.
    2. Tham gia giao th√¥ng ƒë∆∞·ªùng b·ªô l√† ho·∫°t ƒë·ªông c·ªßa ng∆∞·ªùi v√† ph∆∞∆°ng ti·ªán giao th√¥ng tr√™n ƒë∆∞·ªùng b·ªô.
    
    CH∆Ø∆†NG II
    QUY·ªÄN V√Ä NGHƒ®A V·ª§ C·ª¶A T·ªî CH·ª®C, C√Å NH√ÇN
    
    M·ª•c 1. Quy·ªÅn v√† nghƒ©a v·ª• chung
    
    ƒêi·ªÅu 3. Quy·ªÅn c·ªßa t·ªï ch·ª©c, c√° nh√¢n
    T·ªï ch·ª©c, c√° nh√¢n c√≥ c√°c quy·ªÅn sau ƒë√¢y:
    1. ƒê∆∞·ª£c s·ª≠ d·ª•ng ƒë∆∞·ªùng b·ªô an to√†n, th√¥ng su·ªët.
    2. ƒê∆∞·ª£c cung c·∫•p th√¥ng tin v·ªÅ giao th√¥ng ƒë∆∞·ªùng b·ªô.
    
    ƒêi·ªÅu 4. Nghƒ©a v·ª• c·ªßa t·ªï ch·ª©c, c√° nh√¢n  
    T·ªï ch·ª©c, c√° nh√¢n c√≥ c√°c nghƒ©a v·ª• sau ƒë√¢y:
    1. Ch·∫•p h√†nh quy t·∫Øc giao th√¥ng ƒë∆∞·ªùng b·ªô.
    2. Tham gia b·∫£o v·ªá k·∫øt c·∫•u h·∫° t·∫ßng giao th√¥ng ƒë∆∞·ªùng b·ªô.
    
    M·ª•c 2. Quy·ªÅn v√† nghƒ©a v·ª• ri√™ng
    
    ƒêi·ªÅu 5. Quy·ªÅn ri√™ng c·ªßa ng∆∞·ªùi ƒëi·ªÅu khi·ªÉn ph∆∞∆°ng ti·ªán
    Ng∆∞·ªùi ƒëi·ªÅu khi·ªÉn ph∆∞∆°ng ti·ªán giao th√¥ng ƒë∆∞·ªùng b·ªô c√≥ quy·ªÅn ƒë∆∞·ª£c ∆∞u ti√™n ƒëi tr∆∞·ªõc trong c√°c tr∆∞·ªùng h·ª£p quy ƒë·ªãnh t·∫°i Lu·∫≠t n√†y.
    
    CH∆Ø∆†NG III
    QUY T·∫ÆC GIAO TH√îNG ƒê∆Ø·ªúNG B·ªò
    
    ƒêi·ªÅu 86. Quy ƒë·ªãnh chuy·ªÉn ti·∫øp
    Lu·∫≠t n√†y c√≥ hi·ªáu l·ª±c thi h√†nh t·ª´ ng√†y 01 th√°ng 01 nƒÉm 2009; c√°c quy ƒë·ªãnh tr∆∞·ªõc ƒë√¢y tr√°i v·ªõi Lu·∫≠t n√†y ƒë·ªÅu b·ªã b√£i b·ªè.
    """
    
    parser = LegalDocumentParser()
    
    # Parse document  
    result = parser.parse_document("Lu·∫≠t Giao th√¥ng ƒë∆∞·ªùng b·ªô", sample_text)
    
    # Pretty print JSON
    print(f"\nüìÑ PARSED DOCUMENT STRUCTURE:")
    print("=" * 80)
    print(json.dumps(result, ensure_ascii=False, indent=2))
    
    # Test getting all articles
    articles = parser.get_all_articles(result)
    print(f"\nüìú ALL ARTICLES FOR MONTE CARLO SAMPLING:")
    print("=" * 80)
    for i, article in enumerate(articles, 1):
        print(f"{i}. Article {article['number']}: {article['title']}")
        print(f"   Path: {article['path']}")
        print(f"   Content length: {article['content_length']} chars")
        print(f"   Preview: {article['content'][:100]}...")
        
    # Test Monte Carlo sampling
    print(f"\nüé≤ MONTE CARLO SAMPLING TEST:")
    print("=" * 80)
    print(f"Total articles available: {len(articles)}")
    
    # Test multiple rounds of Monte Carlo sampling
    sample_sizes = [2, 3, 5]
    
    for sample_size in sample_sizes:
        if sample_size <= len(articles):
            print(f"\nüî• Sample size: {sample_size}")
            selected = parser.monte_carlo_sample_articles(articles, sample_size)
            for i, article in enumerate(selected, 1):
                print(f"  {i}. Article {article['number']}: {article['title']}")
    
    print(f"\n‚úÖ Parser test completed successfully!")
    print(f"üìä Final Stats:")
    print(f"   - Chapters: {result['metadata']['parsing_stats']['chapters']}")
    print(f"   - Sections: {result['metadata']['parsing_stats']['total_sections']}")
    print(f"   - Articles: {result['metadata']['parsing_stats']['articles']}")
    print(f"   - Content Length: {result['content_length']} chars")

if __name__ == "__main__":
    test_parser()
